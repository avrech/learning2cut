""" run_experiment
Launch multiple experiment configurations in parallel on distributed resources.
Requires a .pkl file containing a list of configurations to complete.
This file should be generated by analyze_experiment.py if there are missing results.
"""
from importlib import import_module
from ray import tune
from ray.tune import track
from argparse import ArgumentParser
import pickle
from datetime import datetime

NOW = str(datetime.now())[:-7].replace(' ', '.').replace(':', '-').replace('.', '/')
parser = ArgumentParser()
parser.add_argument('--experiment', type=str, default='variability',
                    help='experiment dir')
parser.add_argument('--log-dir', type=str, default='variability/results/tmp/' + NOW,
                    help='path to results root')
parser.add_argument('--config-file', type=str, default=None,
                    help='path to generate/read data')
args = parser.parse_args()

# load configurations of missing experiments to complete
with open(args.config_file, 'rb') as f:
    configs = pickle.load(f)

# generate tune config for the sweep hparams
tune_config = {'complete_experiment': tune.grid_search(configs)}

# initialize global tracker for all experiments
experiment = import_module('experiments.' + args.experiment + '.experiment')
track.init()

# run experiment
analysis = tune.run(experiment.experiment,
                    config=tune_config,
                    resources_per_trial={'cpu': 1, 'gpu': 0},
                    local_dir=args.log_dir,
                    trial_name_creator=None,
                    max_failures=1  # TODO learn how to recover from checkpoints
                    )
