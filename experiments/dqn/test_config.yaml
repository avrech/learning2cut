# NOTES:
# All intervals are measured in num_param_updates,
# except target_update_interval and param_update_interval which are measured in number of sgd steps done on the learner.
# SINGLE THREAD SETTING:
# - num_policy_updates equals to the number of episodes done and to the number of sgd steps done.
# - it is recommended to sparsify the logs and checkpoints to reduce the tensorboard memory consumption.
# - specifically it is recommended to evaluate the hard validation and test sets in low frequency.
# DISTRIBUTED SETTING:
# - num_policy_updates equals to the number of workers' policy updates, which happen every param_update_interval
# - the hard datasets can be evaluated on the tester in the same frequency as the easy datasets.
# DQN ALGORITHM HPARAMS
batch_size: 4
lr: 0.001
weight_decay: 0.0001
nstep_learning: 8 # 1, 8
target_update_interval: 1000  # num sgd steps between target_net's parameters update
value_aggr: mean
credit_assignment: False  # False, True
gamma: 0.99
eps_start: 0.9
eps_end: 0.05
eps_decay: 100000
replay_buffer_capacity: 65536
dqn_objective: db_auc
empty_action_penalty: 0

# DQN ARCHITECTURE HPARAMS
dqn_arch: TQNet # TQNet , QNet
tqnet_version: v1
emb_dim: 128
cut_conv: CutConv
encoder_cut_conv_layers: 1
encoder_lp_conv_layers: 1
decoder_cut_conv_layers: 1
attention_heads: 4
lp_conv_aggr: mean
cut_conv_aggr: mean

# GENERAL
seed: 259385
hide_scip_output: False
num_episodes: 2000000
log_interval: 20
checkpoint_interval: 20
verbose: 2

# DEBUG FLAGS
debug: False
debug_cuda: False
overfit: validset25
sanity_check: True

# SCIP STUFF
reset_maxcuts_every_round: True  # avoid undesired unoughcuts in scip separationRoundLP
use_general_cuts: False

# CYCLE INEQUALITIES
chordless_only: False
simple_cycle_only: True

# DATASETS
# measured lp_iterations for SCIP solving at the root node only:
# barabasi albert 25 (10000 instances) mean ~ 1.9K, std < 900
# barabasi albert 50 (20 instances) mean ~ 36K, std < 7K
# barabasi albert 100 (20 instances) mean ~ 80K, std ~ 51K
# so we set the lp_iterations_limit to 3K, 50K and 100K for the graphs of 25, 50 and 100 nodes respectively
datasets:
  trainset25:
    lp_iterations_limit: 3000
    ngraphs: 10000
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 46
    graph_size: 25
    dataset_name: trainset25
    time_limit_sec: 600
    baseline_solver: scip
    save_all_stats: False
  validset25:
    lp_iterations_limit: 3000
    eval_interval: 100
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 36
    graph_size: 25
    dataset_name: validset25
    time_limit_sec: 600
    baseline_solver: scip
    save_all_stats: True
  testset25:
    lp_iterations_limit: 3000
    eval_interval: 100
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 223
    graph_size: 25
    dataset_name: testset25
    time_limit_sec: 600
    baseline_solver: scip
    save_all_stats: True
  validset50:
    lp_iterations_limit: 50000
    eval_interval: 500
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 36
    graph_size: 50
    dataset_name: validset50
    time_limit_sec: 3600
    baseline_solver: scip
    save_all_stats: True
  testset50:
    lp_iterations_limit: 50000
    eval_interval: 500
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 223
    graph_size: 50
    dataset_name: testset50
    time_limit_sec: 3600
    baseline_solver: scip
    save_all_stats: True
  validset100:
    lp_iterations_limit: 100000
    eval_interval: 1000
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 36
    graph_size: 100
    dataset_name: validset100
    time_limit_sec: 3600
    baseline_solver: scip
    save_all_stats: True
  testset100:
    lp_iterations_limit: 100000
    eval_interval: 1000
    scip_seed: [52, 176, 223]
    ngraphs: 10
    barabasi_albert_m: 10
    weights: normal  # uniform01 | normal | ones
    graph_type: barabasi-albert
    dataset_generation_seed: 223
    graph_size: 100
    dataset_name: testset100
    time_limit_sec: 3600
    baseline_solver: scip
    save_all_stats: True

# DISTRIBUTED RL PARAMETERS
# Environment parameters
#env_name: PongNoFrameskip-v4 #   CartPole-v1 # LunarLander-v2 #
#atari: True

# Learning parameters
model: Apex-DQN
learner_device: cuda
worker_device: cpu
num_workers: 2
num_learners: 1
#num_step: 3
#batch_size: 512
#max_episode_steps: None
param_update_interval: 100  # number of learner.sgd_steps between workers policy update
max_num_updates: 100000  # relevant to PER to increase beta across time
#tau: 0.01
#learning_rate: 0.0001
#gamma: 0.95
#eps_greedy: 0.20
#eps_decay: 0.95

# Buffer parameters
#buffer_max_size: 1000000
use_per: True
priority_alpha: 0.6
priority_beta: 0.4
priority_beta_start: 0.4
priority_beta_end: 1.0
priority_beta_decay: 100000  # exponentially increase to priority_beta_end like decreasing eps_greedy
worker_buffer_size: 1000
local_buffer_size: 50  # todo tune this parameter on the real distributed program
# Communication configs
params_pubsub_port: 5555
#repreq_port: 5556
#pullpush_port: 5557
replay_server_2_learner_port: 5556
learner_2_replay_server_port: 5557
workers_2_replay_server_port: 5558
replay_buffer_minimum_size: 20